{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OQdPvU8YMGHn723DCZHJtHpdZ1lL6swy",
      "authorship_tag": "ABX9TyO2oAm2kraOROK1aQdTbrGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aitch-cmd/FootfallTracker/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics"
      ],
      "metadata": {
        "id": "XrBHuNVw3Xq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d-whGPu12U_"
      },
      "outputs": [],
      "source": [
        "# Importing the YOLO package from the ultralytics library to use YOLOv8\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the YOLOv8 model using a pre-trained weight file (YOLOv8n - nano version)\n",
        "model = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "uESWEmQX3MIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade supervision"
      ],
      "metadata": {
        "id": "fhm_MN_L5YlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making annotations"
      ],
      "metadata": {
        "id": "yTLez08V6-yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "# Specify the input video path\n",
        "video_path = \"/content/drive/MyDrive/testing-1.mp4\"\n",
        "\n",
        "# Create the video frames generator\n",
        "generator = sv.get_video_frames_generator(video_path)\n",
        "\n",
        "# Create an iterator and get the first frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "# Perform inference on the first frame\n",
        "results = model(frame, imgsz=1280)[0]\n",
        "\n",
        "# Convert inference results to Detections\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "# Create the correct BoxAnnotator object\n",
        "box_annotator = sv.BoxAnnotator(thickness=4)\n",
        "\n",
        "# Annotate the frame with bounding boxes\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "# Display the annotated frame\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "ZTDokvzo37Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding grids"
      ],
      "metadata": {
        "id": "Bq-YIp4o7EaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Specify the video path directly\n",
        "video_path = \"/content/drive/MyDrive/testing-1.mp4\"  # Replace with the actual path to your video\n",
        "\n",
        "# Create the video frames generator\n",
        "generator = sv.get_video_frames_generator(video_path)\n",
        "\n",
        "# Create an iterator and get the first frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "# Define a single zone as a rectangle (x1, y1, x2, y2)\n",
        "zone = {\"x1\": 100, \"y1\": 100, \"x2\": 500, \"y2\": 300}\n",
        "#x1, y1 represent the top-left corner of the rectangle.\n",
        "#x2, y2 represent the bottom-right corner of the rectangle.\n",
        "\n",
        "# Draw the zone on the frame\n",
        "x1, y1, x2, y2 = zone[\"x1\"], zone[\"y1\"], zone[\"x2\"], zone[\"y2\"]\n",
        "cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Draw a rectangle for the zone\n",
        "\n",
        "# Convert frame to RGB for Matplotlib\n",
        "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the frame with the zone\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(frame_rgb)\n",
        "plt.title(\"Frame with Zone\")\n",
        "plt.grid(color='white', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Add grid lines for measurement\n",
        "plt.xticks(np.arange(0, frame_rgb.shape[1], 100))\n",
        "plt.yticks(np.arange(0, frame_rgb.shape[0], 100))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7KYY08wl7F8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Specify the video path directly\n",
        "video_path = \"/content/drive/MyDrive/testing-1.mp4\"\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # or yolov8s.pt, yolov8m.pt etc.\n",
        "\n",
        "# Create the video frames generator\n",
        "generator = sv.get_video_frames_generator(video_path)\n",
        "\n",
        "# Create an iterator and get the first frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "# Perform inference on the first frame\n",
        "results = model(frame)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "# Annotate only bounding boxes (skip label annotation)\n",
        "box_annotator = sv.BoxAnnotator(thickness=4)\n",
        "annotated_frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "# Define a single zone as a rectangle (x1, y1, x2, y2)\n",
        "zone = {\"x1\": 100, \"y1\": 100, \"x2\": 500, \"y2\": 300}\n",
        "\n",
        "# Draw the zone on the frame\n",
        "x1, y1, x2, y2 = zone[\"x1\"], zone[\"y1\"], zone[\"x2\"], zone[\"y2\"]\n",
        "cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Draw a rectangle for the zone\n",
        "\n",
        "# Convert the frame to RGB format for Matplotlib (if needed)\n",
        "annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Plot the annotated frame with grid lines\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(annotated_frame_rgb)\n",
        "plt.title(\"Annotated Frame with Zone and Detections\")\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(color='white', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Set grid properties (optional, e.g., based on pixels)\n",
        "plt.xticks(np.arange(0, annotated_frame_rgb.shape[1], 100))  # Set x-ticks (every 100 pixels)\n",
        "plt.yticks(np.arange(0, annotated_frame_rgb.shape[0], 100))  # Set y-ticks (every 100 pixels)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4-kWJt7_7RNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "q6gmC8ZCM1W6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dwell Time Tracking"
      ],
      "metadata": {
        "id": "G4ppwViRYRU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "\n",
        "def process_video_return_last_frame(video_path, output_path):\n",
        "    model = YOLO('yolov8n.pt')  # Load YOLOv8 model\n",
        "\n",
        "    # Define polygon zone\n",
        "    polygon = np.array([[100, 100], [500, 100], [500, 400], [100, 400]])\n",
        "    zone = sv.PolygonZone(polygon=polygon)\n",
        "    zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color(255, 0, 0))\n",
        "    box_annotator = sv.BoxAnnotator(color=sv.Color(138, 43, 226), thickness=2)\n",
        "\n",
        "    # Video reading\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width, height = int(cap.get(3)), int(cap.get(4))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Heatmap init\n",
        "    heatmap = np.zeros((height, width), dtype=np.float32)\n",
        "    track_memory = {}  # track_id: (cx, cy, time_entered)\n",
        "\n",
        "    # Writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    last_frame = None\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        now = time.time()\n",
        "\n",
        "        results = model.track(frame, persist=True)[0]\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "        detections = detections[detections.class_id == 0]  # Only persons\n",
        "\n",
        "        for i, xyxy in enumerate(detections.xyxy):\n",
        "            if i >= len(detections.tracker_id):\n",
        "                continue\n",
        "\n",
        "            track_id = detections.tracker_id[i]\n",
        "            x1, y1, x2, y2 = map(int, xyxy)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "\n",
        "            if cv2.pointPolygonTest(polygon, (cx, cy), False) >= 0:\n",
        "                if track_id in track_memory:\n",
        "                    old_cx, old_cy, time_entered = track_memory[track_id]\n",
        "                    dist = np.hypot(cx - old_cx, cy - old_cy)\n",
        "\n",
        "                    if dist < 10:\n",
        "                        dwell_time = now - time_entered\n",
        "                        if dwell_time > 5:\n",
        "                            cv2.circle(heatmap, (cx, cy), radius=15, color=5, thickness=-1)\n",
        "                        else:\n",
        "                            cv2.circle(heatmap, (cx, cy), radius=15, color=1, thickness=-1)\n",
        "                    else:\n",
        "                        track_memory[track_id] = (cx, cy, now)\n",
        "                        cv2.circle(heatmap, (cx, cy), radius=15, color=1, thickness=-1)\n",
        "                else:\n",
        "                    track_memory[track_id] = (cx, cy, now)\n",
        "                    cv2.circle(heatmap, (cx, cy), radius=15, color=1, thickness=-1)\n",
        "\n",
        "        # Annotate\n",
        "        annotated = frame.copy()\n",
        "        annotated = zone_annotator.annotate(scene=annotated)\n",
        "        annotated = box_annotator.annotate(scene=annotated, detections=detections)\n",
        "\n",
        "        # Heatmap overlay\n",
        "        blurred = cv2.GaussianBlur(heatmap, (31, 31), 0)\n",
        "        normalized = cv2.normalize(blurred, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        heatmap_colored = cv2.applyColorMap(normalized.astype(np.uint8), cv2.COLORMAP_JET)\n",
        "        overlay = cv2.addWeighted(annotated, 0.7, heatmap_colored, 0.3, 0)\n",
        "\n",
        "\n",
        "        # Count how many people are in the zone\n",
        "        in_zone_mask = zone.trigger(detections=detections)\n",
        "        people_in_zone = np.sum(in_zone_mask)\n",
        "\n",
        "        # Draw live count\n",
        "        # cv2.putText(\n",
        "        #     overlay,\n",
        "        #     f'People in Zone: {int(people_in_zone)}',\n",
        "        #     (50, 50),\n",
        "        #     cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        #     1,\n",
        "        #     (0, 255, 0),\n",
        "        #     2\n",
        "        # )\n",
        "\n",
        "        out.write(overlay)\n",
        "        last_frame = overlay.copy()\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    return output_path, last_frame\n"
      ],
      "metadata": {
        "id": "r-e54BXlgHeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask user for input and output file paths\n",
        "video_path = input(\"Enter path to input video: \").strip()\n",
        "output_path = input(\"Enter path to save output video: \").strip()\n",
        "\n",
        "#Process video\n",
        "final_video_path, last_frame = process_video_return_last_frame(video_path, output_path)\n",
        "\n",
        "#Display the last frame using matplotlib\n",
        "plt.imshow(cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Last Frame of Output Video\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hD8sUduq3vaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/drive/MyDrive/testing-1.mp4\"\n",
        "output_path = \"/content/drive/MyDrive/testdemo01.mp4\"\n",
        "\n",
        "# Process video and get last frame\n",
        "final_video_path, last_frame = process_video_return_last_frame(video_path, output_path)\n",
        "\n",
        "# Display the last frame\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Last Frame of Output Video\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WJp3Z-OZh5AO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}